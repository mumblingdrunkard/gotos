= Golang Teaching OS - gotos (wip)

A framework to teach the concepts of Operating Systems.
Build your very own operating system around emulated hardware.
Arguably, the most important thing that can come out of this project is the system specification.

If an implementation follows the system specification, processes running ON the emulated, virtualized hardware should run flawlessly, albeit with better or worse performance depending on the implementation.

This project is built around emulating a RISC-V CPU and some generic hardware for I/O.
The CPU runs exclusively in User/Application Mode see _The RISC-V Instruction Set Manual: Volume II: Privileged Spec_ <<rv5vol2>> from https://riscv.org/technical/specifications/ , handing control over to the surrounding system (written in Go) when elevated/enhanced privileges are needed such as when performing syscalls.

== Roadmap

=== Emulation

==== riscv32g target

- [ ] RV32I base instructions (37/40)
- [ ] RV32M extension (0/8)
- [ ] RV32A extension (0/11)
- [ ] RV32F extension (0/26)
- [ ] RV32D extension (0/26)
- [ ] Zicsr extension (0/6)
- [ ] Zifencei extension (0/1)

==== Peripherals

- [ ] MMIO

=== OS

- [ ] Syscalls
  - [*] `void _Noreturn sys_exit(int)`
- [ ] Synchronization primitives
- [ ] C standard library
- [ ] Scheduler
- [ ] MMU
- [ ] Filesystem

=== Applications

- [ ] Shell

== Current state

[NOTE]
====
I think this is thread-safe, but I am not sure.
From the information I could find, arrays are thread safe as long as two threads never write to the same part of memory.
This should be fine as the program is only ever read by the cores (threads) and all the cores have their own stack.
====

Currently, the `fib/fib.text` program is loaded at address 0.
Four cores are initialized with their stack pointer at different locations in memory.
The four cores then run in parallel until halting.
Memory without locking is significantly faster than memory with locking.
This is a problem because in theory, multiple cores may access the same part of memory.

.Perhaps use some sort of frames?
Have one large array for memory, divide this into frames, then have one RWMutex for each frame.
Could try this out, though I believe caching is the way to go here.
Caching means each core has their own copy of non-atomic data such as instructions and stack.
This encompasses most of the memory accesses that a core might deal with leading to a significant speedup for non-atomic reads and writes (which is most of them).

Perhaps have a channel for the memory interface?

== Authors and acknowledgment

.Authors
- mumblingdrunkard

== License

This project is licensed under the traditional MIT license.

[bibliography]
== Bibliography

- [[[rv5vol1]]] Andrew Waterman, Krste Asanović, John Hauser.
_RISC-V ISA Specification: Volume 1, Unprivileged ISA v. 20191213_
- [[[rv5vol2]]] Andrew Waterman, Krste Asanović, John Hauser.
_RISC-V ISA Specification: Volume 2, Privileged Spec v. 20211203_
